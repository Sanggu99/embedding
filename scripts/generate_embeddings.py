import json
import os
import sys
from pathlib import Path
import numpy as np
import torch
from PIL import Image
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel
import umap
from sklearn.preprocessing import MinMaxScaler

# ì„¤ì • ë¡œë“œ
def load_config():
    config_path = Path(__file__).parent.parent / "config.json"
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def main():
    print("ğŸš€ 3D ìœ ë‹ˆë²„ìŠ¤ ëª¨ë“œ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    
    # 1. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
    config = load_config()
    source_folders = config['source_folders']
    output_dir = Path(config['output_dir'])
    extensions = config['image_extensions']

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"DEVICE: {device}")

    try:
        model_id = "openai/clip-vit-base-patch32"
        print(f"ğŸ“¦ CLIP ëª¨ë¸ ë¡œë“œ ì¤‘ ({model_id})...")
        model = CLIPModel.from_pretrained(model_id).to(device)
        processor = CLIPProcessor.from_pretrained(model_id)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("pip install transformers torch pillow umap-learn scikit-learn tqdm ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 2. ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    print("ğŸ“‚ ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
    image_paths = []
    for folder in source_folders:
        folder_path = Path(folder)
        for ext in extensions:
            image_paths.extend(list(folder_path.rglob(f"*{ext}")))
    
    # ì¤‘ë³µ ë° ì‹œìŠ¤í…œ íŒŒì¼ ì œê±°
    image_paths = sorted(list(set([p for p in image_paths if not p.name.startswith('._')])))
    print(f"âœ“ ì´ {len(image_paths)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")

    if not image_paths:
        print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2.5 ë©”íƒ€ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
    metadata_path = output_dir / "public" / "data" / "image_metadata.json"
    metadata_map = {}
    if metadata_path.exists():
        with open(metadata_path, 'r', encoding='utf-8') as f:
            meta_json = json.load(f)
            for item in meta_json:
                metadata_map[item['filename']] = item
    else:
        print("âš ï¸ image_metadata.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íƒ€ì… ë¶„ë¥˜ê°€ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 3. íŠ¹ì§• ì¶”ì¶œ (Feature Extraction) & Zero-shot Classification ì¤€ë¹„
    print("ğŸ§  íŠ¹ì§• ì¶”ì¶œ ë° Zero-shot Classification ì¤‘...")
    
    # í´ë˜ìŠ¤ ì •ì˜ (Zero-shot) - í´ëŸ¬ìŠ¤í„°ë§ í™•ì¥
    class_names = ["exterior", "interior", "aerial", "nature"]
    class_prompts = [
        "exterior architecture photo", 
        "interior design photo", 
        "aerial view of city or building plan", 
        "nature landscape, forest, or mountains"
    ]
    
    # í…ìŠ¤íŠ¸ íŠ¹ì§• ë¯¸ë¦¬ ê³„ì‚°
    try:
        text_inputs = processor(text=class_prompts, return_tensors="pt", padding=True).to(device)
        with torch.no_grad():
            text_outputs = model.get_text_features(**text_inputs)
            
            # í…ìŠ¤íŠ¸ ì¶œë ¥ ì²˜ë¦¬
            if not isinstance(text_outputs, torch.Tensor):
                if hasattr(text_outputs, 'text_embeds'):
                    text_features = text_outputs.text_embeds
                elif hasattr(text_outputs, 'pooler_output'):
                    text_features = text_outputs.pooler_output
                else:
                    text_features = text_outputs
            else:
                text_features = text_outputs

            # ì •ê·œí™”
            import torch.nn.functional as F
            text_features = F.normalize(text_features, p=2, dim=-1)
            print("âœ“ í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
            
    except Exception as e:
        print(f"âš ï¸ í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        text_features = None

    features_list = []
    valid_images = []
    classified_types = [] # ìƒˆë¡œ ë¶„ë¥˜ëœ íƒ€ì… ì €ì¥
    
    batch_size = 32
    
    for i in tqdm(range(0, len(image_paths), batch_size)):
        batch_paths = image_paths[i:i + batch_size]
        batch_images = []
        current_batch_indices = []
        
        for idx, path in enumerate(batch_paths):
            try:
                image = Image.open(path).convert('RGB')
                batch_images.append(image)
                current_batch_indices.append(idx)
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ({path.name}): {e}")
        
        if not batch_images:
            continue

        try:
            inputs = processor(images=batch_images, return_tensors="pt", padding=True).to(device)
            with torch.no_grad():
                outputs = model.get_image_features(**inputs)
            
            # If outputs is not a tensor, try to extract the tensor
            if not isinstance(outputs, torch.Tensor):
                if hasattr(outputs, 'image_embeds'):
                    outputs = outputs.image_embeds
                elif hasattr(outputs, 'pooler_output'):
                    outputs = outputs.pooler_output
            
            # ì •ê·œí™”
            import torch.nn.functional as F
            image_features = F.normalize(outputs, p=2, dim=-1)
            
            features_list.append(image_features.cpu().numpy())
            
            # Zero-shot Classification ìˆ˜í–‰
            if text_features is not None:
                # Similarity: (Batch, Feature) @ (Feature, Classes).T = (Batch, Classes)
                similarity = (image_features @ text_features.T).softmax(dim=-1)
                top_class_indices = similarity.argmax(dim=-1)
                
                for class_idx in top_class_indices:
                    classified_types.append(class_names[class_idx.item()])
            else:
                # í…ìŠ¤íŠ¸ íŠ¹ì§• ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                for _ in range(image_features.shape[0]):
                    classified_types.append("other")

            # ìœ íš¨í•œ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
            for idx in current_batch_indices:
                valid_images.append(batch_paths[idx])
                
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()

    if not features_list:
        print("âŒ ì¶”ì¶œëœ íŠ¹ì§•ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_features = np.concatenate(features_list, axis=0)
    print(f"âœ“ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {all_features.shape}")

    # 4. ì°¨ì› ì¶•ì†Œ (UMAP)
    print("ğŸ“‰ UMAPìœ¼ë¡œ 3ì°¨ì› ì°¨ì› ì¶•ì†Œ ì¤‘...")
    try:
        reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)
        embedding = reducer.fit_transform(all_features)
    except Exception as e:
        print(f"âŒ UMAP ì˜¤ë¥˜: {e}")
        return

    # 5. ì¢Œí‘œ ì •ê·œí™” (-50 ~ 50 ë²”ìœ„ë¡œ ì¡°ì •)
    scaler = MinMaxScaler(feature_range=(-50, 50))
    embedding_scaled = scaler.fit_transform(embedding)

    # 6. ê²°ê³¼ ì €ì¥ (JSON)
    print("ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    output_data = []

    for i, path in enumerate(valid_images):
        filename = path.name
        
        # ë©”íƒ€ë°ì´í„° ë§¤ì¹­ - íŒŒì¼ëª… ê¸°ì¤€ (ê¸°ì¡´ ì •ë³´)
        meta = metadata_map.get(filename, {})
        
        # âš ï¸ ì¤‘ìš”: Zero-shot Classification ê²°ê³¼ ìš°ì„  ì‚¬ìš©
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ê°€ 'exterior' (ê¸°ë³¸ê°’) ì´ê±°ë‚˜ 'other' ì¸ ê²½ìš°, ìƒˆë¡œ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ ì‚¬ìš©
        old_type = meta.get('type', 'other')
        new_type = classified_types[i]
        
        if old_type in ['exterior', 'other'] and new_type != 'other':
            img_type = new_type
            # ë®ì–´ì“°ê¸° ë¡œê¹… (ì„ íƒì‚¬í•­)
            # if i < 5: print(f"Update: {filename[:20]}... {old_type} -> {new_type}")
        else:
            img_type = old_type

        is_architecture = meta.get('is_architecture', True)
        description = meta.get('description', '')
        
        # ì¸ë„¤ì¼ ê²½ë¡œ ê²°ì • ìš°ì„ ìˆœìœ„:
        # 1. ë©”íƒ€ë°ì´í„°ì— ìˆëŠ” path (ê°€ì¥ ì •í™•)
        # 2. configì˜ source_folder ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
        if 'path' in meta:
            rel_path = meta['path']
        else:
            try:
                # E:\4. Midjourney\Midjourney 8\... -> Midjourney 8\...
                # source_folders[0]ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                rel_path = str(path.relative_to(Path(source_folders[0]).parent)).replace('\\', '/')
            except:
                rel_path = str(path).replace('\\', '/')

        output_data.append({
            "id": i,
            "x": float(embedding_scaled[i, 0]),
            "y": float(embedding_scaled[i, 1]),
            "z": float(embedding_scaled[i, 2]),
            "filename": filename,
            "path": rel_path,
            "type": img_type,
            "is_architecture": is_architecture,
            "description": description
        })

        output_data.append({
            "id": i,
            "x": float(embedding_scaled[i, 0]),
            "y": float(embedding_scaled[i, 1]),
            "z": float(embedding_scaled[i, 2]),
            "filename": filename,
            "path": rel_path,
            "type": img_type,
            "is_architecture": is_architecture,
            "description": description
        })

    output_file = output_dir / "public" / "data" / "coordinates.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… ì™„ë£Œ! íŒŒì¼ ì €ì¥ë¨: {output_file}")

if __name__ == "__main__":
    main()
